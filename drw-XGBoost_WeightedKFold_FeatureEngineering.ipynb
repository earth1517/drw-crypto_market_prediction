{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6589200d",
   "metadata": {},
   "source": [
    "# Crypto Market Price Movement Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f011b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029a34a0",
   "metadata": {},
   "source": [
    "## CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f01e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= CONFIGURATION =======================\n",
    "# --- Paths ---\n",
    "TRAIN_PATH = \"/kaggle/input/drw-crypto-market-prediction/train.parquet\"\n",
    "TEST_PATH = \"/kaggle/input/drw-crypto-market-prediction/test.parquet\"\n",
    "SUB_PATH = \"/kaggle/input/drw-crypto-market-prediction/sample_submission.csv\"\n",
    "OUT_PATH = \"submission.csv\"\n",
    "\n",
    "# --- Feature config ---\n",
    "# Select features based on SHAP values using XGBoost trained on all features with OPTUNA for hyperparameter tuning\n",
    "# Ref: https://www.kaggle.com/code/sadettinamilverdil/yat-r-m-tavsiyesi-de-ildir/comments\n",
    "BASE_FEATURES = [\n",
    "    \"X863\", \"X856\", \"X598\", \"X862\", \"X385\", \"X852\", \"X603\", \"X860\", \"X674\",\n",
    "    \"X415\", \"X345\", \"X855\", \"X174\", \"X302\", \"X178\", \"X168\", \"X612\", \"X888\", \"X421\", \"X333\",\n",
    "    \"buy_qty\", \"sell_qty\", \"volume\", \"bid_qty\", \"ask_qty\"\n",
    "]\n",
    "\n",
    "ENGINEERED_FEATURES = [\n",
    "    'liquidity_ratio', 'buy_sell_interaction', 'log_volume', 'bid_buy_interaction',\n",
    "    'volume_weighted_ask', 'market_activity', 'volume_participation', 'total_liquidity',\n",
    "    'bid_sell_interaction', 'normalized_sell_volume', 'realized_volatility_proxy',\n",
    "    'effective_spread_proxy', 'bid_ask_imbalance'\n",
    "]\n",
    "\n",
    "FEATURES = BASE_FEATURES + ENGINEERED_FEATURES\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "FOLDS = 5\n",
    "\n",
    "# XGBoost parameters based on Optuna hyperparameter tuning\n",
    "# Ref: https://www.kaggle.com/code/sadettinamilverdil/yat-r-m-tavsiyesi-de-ildir/comments\n",
    "XGB_PARAMS = {\n",
    "    \"tree_method\": \"gpu_hist\",\n",
    "    \"colsample_bylevel\": 0.4778,\n",
    "    \"colsample_bynode\": 0.3628,\n",
    "    \"colsample_bytree\": 0.7107,\n",
    "    \"gamma\": 1.7095,\n",
    "    \"learning_rate\": 0.02213,\n",
    "    \"max_depth\": 20,\n",
    "    \"max_leaves\": 12,\n",
    "    \"min_child_weight\": 16,\n",
    "    \"n_estimators\": 1667,\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"reg_alpha\": 39.3524,\n",
    "    \"reg_lambda\": 75.4484,\n",
    "    \"subsample\": 0.06567,\n",
    "    \"verbosity\": 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff355baa",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670b202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= FUNCTIONS =======================\n",
    "# This function reduces memory usage of a DataFrame by downcasting numeric types and converting object types to categories where appropriate.\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    start_mem = df.memory_usage(deep=True).sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if pd.api.types.is_numeric_dtype(col_type):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type).startswith('int'):\n",
    "                if c_min >= 0:\n",
    "                    if c_max < 255:\n",
    "                        df[col] = df[col].astype(np.uint8)\n",
    "                    elif c_max < 65535:\n",
    "                        df[col] = df[col].astype(np.uint16)\n",
    "                    elif c_max < 4294967295:\n",
    "                        df[col] = df[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif col_type == object:\n",
    "            num_unique_values = df[col].nunique()\n",
    "            num_total_values = len(df[col])\n",
    "            if num_unique_values / num_total_values < 0.5:\n",
    "                df[col] = df[col].astype('category')\n",
    "    end_mem = df.memory_usage(deep=True).sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(f\"Mem. usage decreased from {start_mem:.2f} MB to {end_mem:.2f} MB \"\n",
    "              f\"({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)\")\n",
    "    return df\n",
    "\n",
    "# This function fills missing values in a DataFrame using forward and backward fill methods, and replaces infinite values with NaN.\n",
    "def fill_and_clean(df):\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    return df\n",
    "\n",
    "# This function performs feature engineering on the DataFrame by creating new features based on existing ones.\n",
    "# Ref1: https://www.kaggle.com/code/taylorsamarel/low-signal-to-noise/notebook\n",
    "# Ref2: https://www.kaggle.com/code/yangq369/drw-lightgbm-fold\n",
    "def feature_engineering(df):\n",
    "    df['liquidity_ratio'] = (df['bid_qty'] + df['ask_qty']) / (df['volume'] + 1e-8)\n",
    "    df['buy_sell_interaction'] = df['buy_qty'] * df['sell_qty']\n",
    "    df['log_volume'] = np.log1p(df['volume'])\n",
    "    df['bid_buy_interaction'] = df['bid_qty'] * df['buy_qty']\n",
    "    df['volume_weighted_ask'] = df['ask_qty'] * df['volume']\n",
    "    df['market_activity'] = df['volume'] * (df['bid_qty'] + df['ask_qty'])\n",
    "    df['volume_participation'] = (df['buy_qty'] + df['sell_qty']) / ((df['bid_qty'] + df['ask_qty']) + 1e-8)\n",
    "    df['total_liquidity'] = df['bid_qty'] + df['ask_qty']\n",
    "    df['bid_sell_interaction'] = df['bid_qty'] * df['sell_qty']\n",
    "    df['normalized_sell_volume'] = df['sell_qty'] / (df['ask_qty'] + 1e-8)\n",
    "    \n",
    "    # To compute realized_volatility_proxy and effective_spread_proxy, need order_flow_imbalance as intermediate\n",
    "    df['order_flow_imbalance'] = (df['buy_qty'] - df['sell_qty']) / (df['buy_qty'] + df['sell_qty'] + 1e-8)\n",
    "    df['realized_volatility_proxy'] = np.abs(df['order_flow_imbalance']) * df['volume']\n",
    "    df['effective_spread_proxy'] = np.abs(df['buy_qty'] - df['sell_qty']) / (df['volume'] + 1e-8)\n",
    "    df['bid_ask_imbalance'] = (df['bid_qty'] - df['ask_qty']) / (df['bid_qty'] + df['ask_qty'] + 1e-8)\n",
    "    return df\n",
    "\n",
    "# This function loads training and testing data from specified paths.\n",
    "def load_data(train_path, test_path):\n",
    "    train = pd.read_parquet(train_path)\n",
    "    test = pd.read_parquet(test_path)\n",
    "    return train, test\n",
    "\n",
    "# This function prepares the data by reducing memory usage, filling missing values, and performing feature engineering.\n",
    "def prepare_data(train, test):\n",
    "    train = reduce_mem_usage(train)\n",
    "    test = reduce_mem_usage(test)\n",
    "    train = train.reset_index().rename(columns={'index': 'timestamp'})\n",
    "    test = test.reset_index().rename(columns={'index': 'ID'})\n",
    "    train = fill_and_clean(train)\n",
    "    test = fill_and_clean(test)\n",
    "    train = feature_engineering(train)\n",
    "    test = feature_engineering(test)\n",
    "    return train, test\n",
    "\n",
    "# This function trains an XGBoost model using cross-validation and returns predictions for the test set.\n",
    "def train_xgboost_cv(X, y, X_test, xgb_params, folds=5, weighted=True):\n",
    "    kf = KFold(n_splits=folds) # , shuffle=True, random_state=RANDOM_STATE)\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    fold_scores = []\n",
    "    fold_test_preds = []\n",
    "\n",
    "    for i, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"Fold: {i + 1}\")\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "        model = xgb.XGBRegressor(**xgb_params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=0)\n",
    "        val_pred = model.predict(X_valid)\n",
    "        oof_preds[valid_idx] = val_pred\n",
    "        test_pred_fold = model.predict(X_test)\n",
    "        fold_test_preds.append(test_pred_fold)\n",
    "        fold_score = pearsonr(y_valid, val_pred)[0]\n",
    "        fold_scores.append(fold_score)\n",
    "        print(f\"Fold {i + 1} RMSE: {np.sqrt(mean_squared_error(y_valid, val_pred)):.4f} | Pearson: {fold_score:.4f}\")\n",
    "\n",
    "    # Calculate final predictions using both OOF simple average and weighted average \n",
    "    # **Options to use either for submission, Select based on performance**\n",
    "    if weighted:\n",
    "        # Weighted average for test predictions\n",
    "        weights = np.array(fold_scores)\n",
    "        weights = weights / weights.sum()\n",
    "        weighted_test_preds = np.zeros(len(X_test))\n",
    "        for w, preds in zip(weights, fold_test_preds):\n",
    "            weighted_test_preds += w * preds\n",
    "    else:\n",
    "        # Simple average for test predictions\n",
    "        test_preds = np.mean(fold_test_preds, axis=0)\n",
    "\n",
    "    print(\"Final RMSE on OOF:\", np.sqrt(mean_squared_error(y, oof_preds)))\n",
    "    pearson_score = pearsonr(y, oof_preds)[0]\n",
    "    print(\"Final Pearson Correlation =\", pearson_score)\n",
    "    print(\"Test predictions shape:\", test_preds.shape)\n",
    "    print(\"Weighted test predictions shape:\", weighted_test_preds.shape)\n",
    "    print(\"Weights used for each fold:\", weights)\n",
    "    return test_preds, weighted_test_preds\n",
    "\n",
    "# This function saves the predictions to a CSV file for submission.\n",
    "def save_submission(test_preds, out_path, sub_path=SUB_PATH):\n",
    "    sub = pd.read_csv(sub_path)\n",
    "    sub['prediction'] = test_preds\n",
    "    sub.to_csv(out_path, index=False)\n",
    "    print(f\"Submission saved to {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79fac49",
   "metadata": {},
   "source": [
    "## MAIN SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c3eba14",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/drw-crypto-market-prediction/train.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ======================= MAIN SCRIPT =======================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 4\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEST_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m prepare_data(train, test)\n\u001b[0;32m      6\u001b[0m     train_data_reduced \u001b[38;5;241m=\u001b[39m train[FEATURES \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "Cell \u001b[1;32mIn[6], line 73\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(train_path, test_path)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(train_path, test_path):\n\u001b[1;32m---> 73\u001b[0m     train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(test_path)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train, test\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    275\u001b[0m         path_or_handle,\n\u001b[0;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    280\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/drw-crypto-market-prediction/train.parquet'"
     ]
    }
   ],
   "source": [
    "# ======================= MAIN SCRIPT =======================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train, test = load_data(TRAIN_PATH, TEST_PATH)\n",
    "    train, test = prepare_data(train, test)\n",
    "    train_data_reduced = train[FEATURES + ['label']]\n",
    "    test_data_reduced = test[FEATURES + ['label']]\n",
    "    X = train_data_reduced.drop(columns=['label'])\n",
    "    y = train_data_reduced['label']\n",
    "    X_test = test_data_reduced.drop(columns=['label'])\n",
    "    test_preds, weighted_test_preds = train_xgboost_cv(X, y, X_test, XGB_PARAMS, folds=FOLDS, weighted=False) # Choose weighted=False for simple average\n",
    "    save_submission(test_preds, OUT_PATH, SUB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3363750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c drw-crypto-market-prediction -f submission.csv -m \"XGBoost with Weighted KFold + Feature Engineering\" --quiet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
