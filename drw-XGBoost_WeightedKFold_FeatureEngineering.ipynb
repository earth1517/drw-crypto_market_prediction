{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6589200d",
   "metadata": {},
   "source": [
    "# Crypto Market Price Movement Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f011b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029a34a0",
   "metadata": {},
   "source": [
    "## CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f01e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= CONFIGURATION =======================\n",
    "# --- Paths ---\n",
    "TRAIN_PATH = \"/kaggle/input/drw-crypto-market-prediction/train.parquet\"\n",
    "TEST_PATH = \"/kaggle/input/drw-crypto-market-prediction/test.parquet\"\n",
    "SUB_PATH = \"/kaggle/input/drw-crypto-market-prediction/sample_submission.csv\"\n",
    "OUT_PATH = \"submission.csv\"\n",
    "\n",
    "# --- Feature config ---\n",
    "# Select features based on SHAP values using XGBoost trained on all features with OPTUNA for hyperparameter tuning\n",
    "# Ref: https://www.kaggle.com/code/sadettinamilverdil/yat-r-m-tavsiyesi-de-ildir/comments\n",
    "BASE_FEATURES = [\n",
    "    \"X863\", \"X856\", \"X598\", \"X862\", \"X385\", \"X852\", \"X603\", \"X860\", \"X674\",\n",
    "    \"X415\", \"X345\", \"X855\", \"X174\", \"X302\", \"X178\", \"X168\", \"X612\", \"X888\", \"X421\", \"X333\",\n",
    "    \"buy_qty\", \"sell_qty\", \"volume\", \"bid_qty\", \"ask_qty\"\n",
    "]\n",
    "\n",
    "ENGINEERED_FEATURES = [\n",
    "    'liquidity_ratio', 'buy_sell_interaction', 'log_volume', 'bid_buy_interaction',\n",
    "    'volume_weighted_ask', 'market_activity', 'volume_participation', 'total_liquidity',\n",
    "    'bid_sell_interaction', 'normalized_sell_volume', 'realized_volatility_proxy',\n",
    "    'effective_spread_proxy', 'bid_ask_imbalance'\n",
    "]\n",
    "\n",
    "FEATURES = BASE_FEATURES + ENGINEERED_FEATURES\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "FOLDS = 5\n",
    "\n",
    "# XGBoost parameters based on Optuna hyperparameter tuning\n",
    "# Ref: https://www.kaggle.com/code/sadettinamilverdil/yat-r-m-tavsiyesi-de-ildir/comments\n",
    "XGB_PARAMS = {\n",
    "    \"tree_method\": \"gpu_hist\",\n",
    "    \"colsample_bylevel\": 0.4778,\n",
    "    \"colsample_bynode\": 0.3628,\n",
    "    \"colsample_bytree\": 0.7107,\n",
    "    \"gamma\": 1.7095,\n",
    "    \"learning_rate\": 0.02213,\n",
    "    \"max_depth\": 20,\n",
    "    \"max_leaves\": 12,\n",
    "    \"min_child_weight\": 16,\n",
    "    \"n_estimators\": 1667,\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"reg_alpha\": 39.3524,\n",
    "    \"reg_lambda\": 75.4484,\n",
    "    \"subsample\": 0.06567,\n",
    "    \"verbosity\": 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff355baa",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= FUNCTIONS =======================\n",
    "# This function reduces memory usage of a DataFrame by downcasting numeric types and converting object types to categories where appropriate.\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    start_mem = df.memory_usage(deep=True).sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if pd.api.types.is_numeric_dtype(col_type):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type).startswith('int'):\n",
    "                if c_min >= 0:\n",
    "                    if c_max < 255:\n",
    "                        df[col] = df[col].astype(np.uint8)\n",
    "                    elif c_max < 65535:\n",
    "                        df[col] = df[col].astype(np.uint16)\n",
    "                    elif c_max < 4294967295:\n",
    "                        df[col] = df[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif col_type == object:\n",
    "            num_unique_values = df[col].nunique()\n",
    "            num_total_values = len(df[col])\n",
    "            if num_unique_values / num_total_values < 0.5:\n",
    "                df[col] = df[col].astype('category')\n",
    "    end_mem = df.memory_usage(deep=True).sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(f\"Mem. usage decreased from {start_mem:.2f} MB to {end_mem:.2f} MB \"\n",
    "              f\"({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)\")\n",
    "    return df\n",
    "\n",
    "# This function fills missing values in a DataFrame using forward and backward fill methods, and replaces infinite values with NaN.\n",
    "def fill_and_clean(df):\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    return df\n",
    "\n",
    "# This function performs feature engineering on the DataFrame by creating new features based on existing ones.\n",
    "# Ref1: https://www.kaggle.com/code/taylorsamarel/low-signal-to-noise/notebook\n",
    "# Ref2: https://www.kaggle.com/code/yangq369/drw-lightgbm-fold\n",
    "def feature_engineering(df):\n",
    "    df['liquidity_ratio'] = (df['bid_qty'] + df['ask_qty']) / (df['volume'] + 1e-8)\n",
    "    df['buy_sell_interaction'] = df['buy_qty'] * df['sell_qty']\n",
    "    df['log_volume'] = np.log1p(df['volume'])\n",
    "    df['bid_buy_interaction'] = df['bid_qty'] * df['buy_qty']\n",
    "    df['volume_weighted_ask'] = df['ask_qty'] * df['volume']\n",
    "    df['market_activity'] = df['volume'] * (df['bid_qty'] + df['ask_qty'])\n",
    "    df['volume_participation'] = (df['buy_qty'] + df['sell_qty']) / ((df['bid_qty'] + df['ask_qty']) + 1e-8)\n",
    "    df['total_liquidity'] = df['bid_qty'] + df['ask_qty']\n",
    "    df['bid_sell_interaction'] = df['bid_qty'] * df['sell_qty']\n",
    "    df['normalized_sell_volume'] = df['sell_qty'] / (df['ask_qty'] + 1e-8)\n",
    "    \n",
    "    # To compute realized_volatility_proxy and effective_spread_proxy, need order_flow_imbalance as intermediate\n",
    "    df['order_flow_imbalance'] = (df['buy_qty'] - df['sell_qty']) / (df['buy_qty'] + df['sell_qty'] + 1e-8)\n",
    "    df['realized_volatility_proxy'] = np.abs(df['order_flow_imbalance']) * df['volume']\n",
    "    df['effective_spread_proxy'] = np.abs(df['buy_qty'] - df['sell_qty']) / (df['volume'] + 1e-8)\n",
    "    df['bid_ask_imbalance'] = (df['bid_qty'] - df['ask_qty']) / (df['bid_qty'] + df['ask_qty'] + 1e-8)\n",
    "    return df\n",
    "\n",
    "# This function loads training and testing data from specified paths.\n",
    "def load_data(train_path, test_path):\n",
    "    train = pd.read_parquet(train_path)\n",
    "    test = pd.read_parquet(test_path)\n",
    "    return train, test\n",
    "\n",
    "# This function prepares the data by reducing memory usage, filling missing values, and performing feature engineering.\n",
    "def prepare_data(train, test):\n",
    "    train = reduce_mem_usage(train)\n",
    "    test = reduce_mem_usage(test)\n",
    "    train = train.reset_index().rename(columns={'index': 'timestamp'})\n",
    "    test = test.reset_index().rename(columns={'index': 'ID'})\n",
    "    train = fill_and_clean(train)\n",
    "    test = fill_and_clean(test)\n",
    "    train = feature_engineering(train)\n",
    "    test = feature_engineering(test)\n",
    "    return train, test\n",
    "\n",
    "# This function trains an XGBoost model using cross-validation and returns predictions for the test set.\n",
    "def train_xgboost_cv(X, y, X_test, xgb_params, folds=5, weighted=True):\n",
    "    kf = KFold(n_splits=folds) # , shuffle=True, random_state=RANDOM_STATE)\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    fold_scores = []\n",
    "    fold_test_preds = []\n",
    "\n",
    "    for i, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"Fold: {i + 1}\")\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "        model = xgb.XGBRegressor(**xgb_params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=0)\n",
    "        val_pred = model.predict(X_valid)\n",
    "        oof_preds[valid_idx] = val_pred\n",
    "        test_pred_fold = model.predict(X_test)\n",
    "        fold_test_preds.append(test_pred_fold)\n",
    "        fold_score = pearsonr(y_valid, val_pred)[0]\n",
    "        fold_scores.append(fold_score)\n",
    "        print(f\"Fold {i + 1} RMSE: {np.sqrt(mean_squared_error(y_valid, val_pred)):.4f} | Pearson: {fold_score:.4f}\")\n",
    "\n",
    "    # Calculate final predictions using both OOF simple average and weighted average \n",
    "    # **Options to use either for submission, Select based on performance**\n",
    "    if weighted:\n",
    "        # Weighted average for test predictions\n",
    "        weights = np.array(fold_scores)\n",
    "        weights = weights / weights.sum()\n",
    "        weighted_test_preds = np.zeros(len(X_test))\n",
    "        for w, preds in zip(weights, fold_test_preds):\n",
    "            weighted_test_preds += w * preds\n",
    "    else:\n",
    "        # Simple average for test predictions\n",
    "        test_preds = np.mean(fold_test_preds, axis=0)\n",
    "\n",
    "    print(\"Final RMSE on OOF:\", np.sqrt(mean_squared_error(y, oof_preds)))\n",
    "    pearson_score = pearsonr(y, oof_preds)[0]\n",
    "    print(\"Final Pearson Correlation =\", pearson_score)\n",
    "    print(\"Test predictions shape:\", test_preds.shape)\n",
    "    print(\"Weighted test predictions shape:\", weighted_test_preds.shape)\n",
    "    print(\"Weights used for each fold:\", weights)\n",
    "    return test_preds, weighted_test_preds\n",
    "\n",
    "# This function saves the predictions to a CSV file for submission.\n",
    "def save_submission(test_preds, out_path, sub_path=SUB_PATH):\n",
    "    sub = pd.read_csv(sub_path)\n",
    "    sub['prediction'] = test_preds\n",
    "    sub.to_csv(out_path, index=False)\n",
    "    print(f\"Submission saved to {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79fac49",
   "metadata": {},
   "source": [
    "## MAIN SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3eba14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ======================= MAIN SCRIPT =======================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 4\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m(TRAIN_PATH, TEST_PATH)\n\u001b[0;32m      5\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m prepare_data(train, test)\n\u001b[0;32m      6\u001b[0m     train_data_reduced \u001b[38;5;241m=\u001b[39m train[FEATURES \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "# ======================= MAIN SCRIPT =======================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train, test = load_data(TRAIN_PATH, TEST_PATH)\n",
    "    train, test = prepare_data(train, test)\n",
    "    train_data_reduced = train[FEATURES + ['label']]\n",
    "    test_data_reduced = test[FEATURES + ['label']]\n",
    "    X = train_data_reduced.drop(columns=['label'])\n",
    "    y = train_data_reduced['label']\n",
    "    X_test = test_data_reduced.drop(columns=['label'])\n",
    "    test_preds, weighted_test_preds = train_xgboost_cv(X, y, X_test, XGB_PARAMS, folds=FOLDS, weighted=False) # Choose weighted=False for simple average\n",
    "    save_submission(test_preds, OUT_PATH, SUB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3363750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c drw-crypto-market-prediction -f submission.csv -m \"XGBoost with Weighted KFold + Feature Engineering\" --quiet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
